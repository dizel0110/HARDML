{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T17:25:36.699053Z",
     "start_time": "2021-04-14T17:25:36.688638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting solution_4.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile solution_4.py\n",
    "import math\n",
    "import pickle\n",
    "import random\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from catboost.datasets import msrank_10k\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "class Solution:\n",
    "    def __init__(self, n_estimators: int = 100, lr: float = 0.5, ndcg_top_k: int = 10,\n",
    "                 subsample: float = 0.6, colsample_bytree: float = 0.9,\n",
    "                 max_depth: int = 5, min_samples_leaf: int = 8):\n",
    "        self._prepare_data()\n",
    "\n",
    "        self.ndcg_top_k = ndcg_top_k\n",
    "        self.n_estimators = n_estimators\n",
    "        self.lr = lr\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        \n",
    "        self.subsample = subsample\n",
    "        self.colsample_bytree = colsample_bytree\n",
    "        \n",
    "        self.trees = [\n",
    "            DecisionTreeRegressor(\n",
    "                max_depth=11,\n",
    "                min_samples_leaf=75,\n",
    "                random_state=i,\n",
    "            ) \n",
    "            for i in np.arange(n_estimators)\n",
    "        ]\n",
    "        self.features_ids = []\n",
    "        self.n_trees_used = n_estimators\n",
    "\n",
    "    def _get_data(self) -> List[np.ndarray]:\n",
    "        train_df, test_df = msrank_10k()\n",
    "\n",
    "        X_train = train_df.drop([0, 1], axis=1).values\n",
    "        y_train = train_df[0].values\n",
    "        query_ids_train = train_df[1].values.astype(int)\n",
    "\n",
    "        X_test = test_df.drop([0, 1], axis=1).values\n",
    "        y_test = test_df[0].values\n",
    "        query_ids_test = test_df[1].values.astype(int)\n",
    "\n",
    "        return [X_train, y_train, query_ids_train, X_test, y_test, query_ids_test]\n",
    "\n",
    "    def _prepare_data(self) -> None:\n",
    "        (X_train, y_train, self.query_ids_train,\n",
    "            X_test, y_test, self.query_ids_test) = self._get_data()\n",
    "        X_train = self._scale_features_in_query_groups(X_train, self.query_ids_train)\n",
    "        X_test = self._scale_features_in_query_groups(X_test, self.query_ids_test)\n",
    "        \n",
    "        self.X_train = torch.FloatTensor(X_train)\n",
    "        self.X_test = torch.FloatTensor(X_test)\n",
    "        self.ys_train = torch.FloatTensor(y_train).reshape(-1,1)\n",
    "        self.ys_test = torch.FloatTensor(y_test).reshape(-1,1)\n",
    "\n",
    "    def _scale_features_in_query_groups(self, inp_feat_array: np.ndarray,\n",
    "                                        inp_query_ids: np.ndarray) -> np.ndarray:\n",
    "        for id_ in np.unique(inp_query_ids):\n",
    "            mask = inp_query_ids == id_\n",
    "            inp_feat_array[mask, :] = StandardScaler().fit_transform(inp_feat_array[mask])\n",
    "        return inp_feat_array\n",
    "\n",
    "    def _train_one_tree(self, cur_tree_idx: int,\n",
    "                        train_preds: torch.FloatTensor\n",
    "                        ) -> Tuple[DecisionTreeRegressor, np.ndarray]:\n",
    "        np.random.seed(cur_tree_idx)\n",
    "        \n",
    "        lambdas = torch.zeros_like(train_preds)\n",
    "        for query in np.unique(self.query_ids_train):\n",
    "            mask = self.query_ids_train == query\n",
    "            if self.ys_train[mask].sum() != 0:\n",
    "                lambdas[mask] = self._compute_lambdas(self.ys_train[mask],\n",
    "                                                      train_preds[mask])\n",
    "        \n",
    "        N_samples = self.X_train.shape[0]\n",
    "        N_features = self.X_train.shape[1]\n",
    "        samples_idx = np.random.permutation(N_samples)[:int(N_samples*self.subsample)]\n",
    "        feaures_idx = np.random.permutation(N_features)[:int(N_features*self.colsample_bytree)]\n",
    "        \n",
    "        X_train = self.X_train[samples_idx][:,feaures_idx]\n",
    "        y_train = -lambdas[samples_idx]\n",
    "        \n",
    "        tree = self.trees[cur_tree_idx]\n",
    "        tree.fit(X_train, y_train)\n",
    "        return tree, feaures_idx\n",
    "        \n",
    "\n",
    "    def _calc_data_ndcg(self, queries_list: np.ndarray,\n",
    "                        true_labels: torch.FloatTensor, preds: torch.FloatTensor) -> float:\n",
    "        ndcgs = []\n",
    "        for query in np.unique(queries_list):\n",
    "            mask = queries_list == query\n",
    "            try:\n",
    "                ndcgs.append(self._ndcg_k(true_labels[mask], preds[mask], self.ndcg_top_k))\n",
    "            except Exception as ex:\n",
    "                print(query, ex)\n",
    "                ndcgs.append(0.0)\n",
    "        return np.mean(ndcgs)\n",
    "\n",
    "\n",
    "    def fit(self):\n",
    "        np.random.seed(0)\n",
    "        \n",
    "        self.best_ndcg = 0.0\n",
    "        self.ndcgs = []\n",
    "        train_preds = torch.zeros_like(self.ys_train)\n",
    "        test_preds = torch.zeros_like(self.ys_test)\n",
    "        for ind in np.arange(self.n_estimators):\n",
    "            tree, features_idx = self._train_one_tree(ind, train_preds)\n",
    "            self.features_ids.append(features_idx)\n",
    "                        \n",
    "            train_preds += self.lr * tree.predict(self.X_train[:, features_idx]).reshape(-1, 1)\n",
    "            test_preds += self.lr * tree.predict(self.X_test[:, features_idx]).reshape(-1, 1)\n",
    "            \n",
    "            self.ndcgs.append(self._calc_data_ndcg(self.query_ids_test, self.ys_test, test_preds))\n",
    "            if self.ndcgs[-1] > self.best_ndcg:\n",
    "                self.best_ndcg = self.ndcgs[-1]\n",
    "        \n",
    "        self.n_trees_used = np.argmax(self.ndcgs) + 1\n",
    "        self.trees = self.trees[:self.n_trees_used]\n",
    "        self.features_ids = self.features_ids[:self.n_trees_used]\n",
    "            \n",
    "    def predict(self, data: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        pred = torch.zeros(data.shape[0], 1)\n",
    "        for tree, features_idx in zip(self.trees, self.features_ids):\n",
    "            pred += self.lr * tree.predict(data[:, features_idx]).reshape(-1, 1)\n",
    "        return pred\n",
    "            \n",
    "\n",
    "    def _compute_lambdas(self, y_true: torch.FloatTensor, y_pred: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        N = 1 / self._dcg_k(y_true, y_true, self.ndcg_top_k)\n",
    "\n",
    "        _, order = torch.sort(y_true, descending=True, axis=0)\n",
    "        order += 1\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pos_pairs_score_diff = 1.0 + torch.exp((y_pred - y_pred.t()))\n",
    "\n",
    "            rel_diff = y_true - y_true.t()\n",
    "            pos_pairs = (rel_diff > 0).type(torch.float32)\n",
    "            neg_pairs = (rel_diff < 0).type(torch.float32)\n",
    "            Sij = pos_pairs - neg_pairs\n",
    "            \n",
    "            gain_diff = torch.pow(2.0, y_true) - torch.pow(2.0, y_true.t())\n",
    "\n",
    "            decay_diff = (1.0 / torch.log2(order + 1.0)) - (1.0 / torch.log2(order.t() + 1.0))\n",
    "            \n",
    "            delta_ndcg = torch.abs(N * gain_diff * decay_diff)\n",
    "\n",
    "            lambdas =  (0.5 * (1 - Sij) - 1 / pos_pairs_score_diff) * delta_ndcg\n",
    "            lambdas = torch.sum(lambdas, dim=1, keepdim=True)\n",
    "\n",
    "            return lambdas\n",
    "\n",
    "    def _dcg_k(self, ys_true: torch.Tensor, ys_pred: torch.Tensor,\n",
    "               ndcg_top_k: int) -> float:\n",
    "        order = ys_pred.argsort(dim=0, descending=True)[:ndcg_top_k]\n",
    "        order = order.reshape(-1)\n",
    "        index = torch.arange(len(order), dtype=torch.float64).reshape(-1, 1)\n",
    "        index += 1\n",
    "        return ((torch.pow(2, ys_true[order]) - 1) / torch.log2(index + 1)).sum().item()\n",
    "    \n",
    "    def _ndcg_k(self, ys_true, ys_pred, ndcg_top_k) -> float:\n",
    "        dcg_val = self._dcg_k(ys_true, ys_pred, ndcg_top_k)\n",
    "        dcg_best_val = self._dcg_k(ys_true, ys_true, ndcg_top_k)\n",
    "        return dcg_val / dcg_best_val\n",
    "\n",
    "    def save_model(self, path: str):\n",
    "        state = {\n",
    "            'trees': self.trees,\n",
    "            'features_ids': self.features_ids,\n",
    "            'n_trees_used': self.n_trees_used,\n",
    "        }\n",
    "        with open(path, 'wb') as file:\n",
    "            pickle.dump(state, file)\n",
    "\n",
    "    def load_model(self, path: str):\n",
    "        with open(path, 'rb') as file:\n",
    "            state = pickle.load(file)\n",
    "        self.trees = state['trees']\n",
    "        self.features_ids = state['features_ids']\n",
    "        self.n_trees_used = state['n_trees_used']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T17:23:48.120823Z",
     "start_time": "2021-04-14T17:23:46.848106Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 667 ms, sys: 92.5 ms, total: 759 ms\n",
      "Wall time: 1.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, rand, tpe\n",
    "import solution_4\n",
    "import importlib\n",
    "importlib.reload(solution_4)\n",
    "\n",
    "s = solution_4.Solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T17:23:49.435882Z",
     "start_time": "2021-04-14T17:23:49.426537Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    s = solution_4.Solution(\n",
    "        n_estimators=10,\n",
    "        max_depth=int(params[0]),\n",
    "        min_samples_leaf=int(params[1]),\n",
    "    )\n",
    "    s.fit()\n",
    "    return -s.best_ndcg"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T16:25:14.684054Z",
     "start_time": "2021-04-14T16:14:07.552378Z"
    }
   },
   "source": [
    "%%time\n",
    "best = fmin(\n",
    "    objective,\n",
    "    space=[\n",
    "        hp.quniform('max_depth', 1, 15, 1),\n",
    "        hp.quniform('min_samples_leaf', 8, 100, 1),\n",
    "    ],\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=100,\n",
    "    trials=Trials(),\n",
    ")\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T17:25:02.729714Z",
     "start_time": "2021-04-14T17:23:57.690693Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 1s, sys: 1.53 s, total: 2min 3s\n",
      "Wall time: 1min 5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4327087454927796"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "s = solution_4.Solution(\n",
    "    n_estimators=100,\n",
    "    max_depth=11,\n",
    "    min_samples_leaf=75,\n",
    ")\n",
    "s.fit()\n",
    "s.best_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T17:25:02.738805Z",
     "start_time": "2021-04-14T17:25:02.732509Z"
    }
   },
   "outputs": [],
   "source": [
    "s.save_model('model_4.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
