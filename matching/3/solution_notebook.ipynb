{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-12T18:11:28.280220Z",
     "start_time": "2021-04-12T18:11:28.264410Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting solution.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile solution_3.py\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from catboost.datasets import msrank_10k\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class ListNet(torch.nn.Module):\n",
    "    def __init__(self, num_input_features: int, hidden_dim: int):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(num_input_features, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(self.hidden_dim, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_1: torch.Tensor) -> torch.Tensor:\n",
    "        logits = self.model(input_1)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class Solution:\n",
    "    def __init__(self, n_epochs: int = 5, listnet_hidden_dim: int = 30,\n",
    "                 lr: float = 0.001, ndcg_top_k: int = 10):\n",
    "        self._prepare_data()\n",
    "        self.num_input_features = self.X_train.shape[1]\n",
    "        self.ndcg_top_k = ndcg_top_k\n",
    "        self.n_epochs = n_epochs\n",
    "\n",
    "        self.model = self._create_model(self.num_input_features, listnet_hidden_dim)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "\n",
    "    def _get_data(self) -> List[np.ndarray]:\n",
    "        train_df, test_df = msrank_10k()\n",
    "\n",
    "        X_train = train_df.drop([0, 1], axis=1).values\n",
    "        y_train = train_df[0].values\n",
    "        query_ids_train = train_df[1].values.astype(int)\n",
    "\n",
    "        X_test = test_df.drop([0, 1], axis=1).values\n",
    "        y_test = test_df[0].values\n",
    "        query_ids_test = test_df[1].values.astype(int)\n",
    "\n",
    "        return [X_train, y_train, query_ids_train, X_test, y_test, query_ids_test]\n",
    "\n",
    "    def _prepare_data(self) -> None:\n",
    "        (\n",
    "            X_train, y_train, self.query_ids_train,\n",
    "            X_test, y_test, self.query_ids_test,\n",
    "        ) = self._get_data()\n",
    "        X_train = self._scale_features_in_query_groups(X_train, self.query_ids_train)\n",
    "        X_test = self._scale_features_in_query_groups(X_test, self.query_ids_test)\n",
    "        \n",
    "        self.X_train = torch.FloatTensor(X_train)\n",
    "        self.X_test = torch.FloatTensor(X_test)\n",
    "        self.ys_train = torch.FloatTensor(y_train)\n",
    "        self.ys_test = torch.FloatTensor(y_test)\n",
    "\n",
    "    def _scale_features_in_query_groups(self, inp_feat_array: np.ndarray,\n",
    "                                        inp_query_ids: np.ndarray) -> np.ndarray:\n",
    "        for id_ in np.unique(inp_query_ids):\n",
    "            mask = inp_query_ids == id_\n",
    "            inp_feat_array[mask, :] = StandardScaler().fit_transform(inp_feat_array[mask])\n",
    "        return inp_feat_array\n",
    "\n",
    "    def _create_model(self, listnet_num_input_features: int,\n",
    "                      listnet_hidden_dim: int) -> torch.nn.Module:\n",
    "        torch.manual_seed(0)\n",
    "        net = ListNet(listnet_num_input_features, listnet_hidden_dim)\n",
    "        return net\n",
    "\n",
    "    def fit(self) -> List[float]:        \n",
    "        epochs = 5\n",
    "        ndcgs = []\n",
    "        for epoch in range(epochs):\n",
    "            self._train_one_epoch()\n",
    "            ndcgs.append(self._eval_test_set())\n",
    "        return ndcgs\n",
    "\n",
    "    def _calc_loss(self, batch_ys: torch.FloatTensor,\n",
    "                   batch_pred: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        P_true = torch.softmax(batch_ys, dim=0)\n",
    "        P_pred = torch.softmax(batch_pred, dim=0)\n",
    "        return -torch.sum(P_true * torch.log(P_pred))\n",
    "\n",
    "    def _train_one_epoch(self) -> None:\n",
    "        self.model.train()\n",
    "        \n",
    "        queries = np.unique(self.query_ids_train)\n",
    "        N_train = len(queries)\n",
    "        batch_size = 20\n",
    "        \n",
    "        idx = torch.randperm(N_train)\n",
    "        \n",
    "        queries = queries[idx]\n",
    "        \n",
    "        cur_batch = 0\n",
    "        for it in range(N_train // batch_size):\n",
    "            batch_queries = queries[cur_batch:cur_batch+batch_size]\n",
    "            for query in batch_queries:\n",
    "                \n",
    "                query_X = self.X_train[self.query_ids_train == query]\n",
    "                query_ys = self.ys_train[self.query_ids_train == query]\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                if len(query_X) > 0:\n",
    "                    query_pred = self.model(query_X).reshape(-1)\n",
    "                    loss = self._calc_loss(query_ys, query_pred)\n",
    "#                     if it % 10:\n",
    "#                         print(f\"Loss: {loss.item():.2f}\")\n",
    "                    loss.backward(retain_graph=True)\n",
    "                    self.optimizer.step()\n",
    "                    \n",
    "#             if it % 10 == 0:\n",
    "#                 print(f\"nDCG: {self._eval_test_set():.2f}\")\n",
    "            cur_batch += batch_size\n",
    "\n",
    "    def _eval_test_set(self) -> float:\n",
    "        with torch.no_grad():\n",
    "            self.model.eval()\n",
    "            ndcgs = []\n",
    "            for query in np.unique(self.query_ids_test):\n",
    "                try:\n",
    "                    query_X = self.X_test[self.query_ids_test == query]\n",
    "                    query_y = self.ys_test[self.query_ids_test == query]\n",
    "                    query_pred = self.model(query_X).reshape(-1)\n",
    "                    ndcgs.append(self._ndcg_k(query_y, query_pred, self.ndcg_top_k))\n",
    "                except Exception as exp:\n",
    "#                     print('Error in dcg: ', exp)\n",
    "                    ndcgs.append(0.0)\n",
    "            return np.mean(ndcgs)\n",
    "\n",
    "    def _dcg_k(self, ys_true: torch.Tensor, ys_pred: torch.Tensor,\n",
    "               ndcg_top_k: int) -> float:\n",
    "        order = ys_pred.argsort(descending=True)[:ndcg_top_k]\n",
    "        index = torch.arange(len(order), dtype=torch.float64) + 1\n",
    "        return ((2**ys_true[order] - 1) / torch.log2(index + 1)).sum().item()\n",
    "        \n",
    "    def _ndcg_k(self, ys_true: torch.Tensor, ys_pred: torch.Tensor,\n",
    "                ndcg_top_k: int) -> float:\n",
    "        \n",
    "        dcg_val = self._dcg_k(ys_true, ys_pred, ndcg_top_k)\n",
    "        dcg_best_val = self._dcg_k(ys_true, ys_true, ndcg_top_k)\n",
    "        return dcg_val / dcg_best_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-12T18:11:59.033143Z",
     "start_time": "2021-04-12T18:11:57.842642Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import solution\n",
    "import importlib\n",
    "importlib.reload(solution)\n",
    "\n",
    "s = solution.Solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-12T18:12:01.758748Z",
     "start_time": "2021-04-12T18:12:00.451078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.25 s, sys: 124 ms, total: 9.37 s\n",
      "Wall time: 1.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.42230032522186406,\n",
       " 0.4305281970712608,\n",
       " 0.4330858948052001,\n",
       " 0.44650492729537383,\n",
       " 0.41933892133113804]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "s.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
